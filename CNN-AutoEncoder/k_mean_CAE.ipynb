{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import scale\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import scale\n",
    "import pylab as pl\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import Binarizer\n",
    "from keras.preprocessing import image\n",
    "import os\n",
    "# %matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows = n_cols = 128\n",
    "n_clusters = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def print_results(a, b,c):\n",
    "    y_train_to_clustered  = np.dstack([y, c])[0]\n",
    "    clustered_tallies = np.zeros((n_clusters, n_clusters), dtype=int)\n",
    "    for i in range(0, len(y_train_to_clustered)):\n",
    "        clustered_tallies[y_train_to_clustered[i][1]][y_train_to_clustered[i][0]] += 1\n",
    "\n",
    "    cluster_to_num_map = list(map(lambda x: np.argmax(x), clustered_tallies))\n",
    "    clustered_tallies = sorted(clustered_tallies, key=lambda e: np.argmax(e)) \n",
    "\n",
    "    fig, ax = plt.subplots(1, figsize=(15,15))\n",
    "    p = sn.heatmap(clustered_tallies, annot=True, fmt=\"d\", annot_kws={\"size\": 10}, cmap='coolwarm', ax=ax, square=True, yticklabels=cluster_to_num_map)\n",
    "    plt.xlabel('Actual', fontsize=18)\n",
    "    plt.ylabel('Cluster', fontsize=18)\n",
    "    p.tick_params(length=0)\n",
    "    p.xaxis.tick_top()\n",
    "    p.xaxis.set_label_position('top')\n",
    "    plt.title('Cluster match count for each number', fontsize= 30)\n",
    "        \n",
    "    # purity - sum of correct in each class divided by the total number of images\n",
    "    purity_sums = np.zeros((10, 1))\n",
    "\n",
    "    for i in range(0, len(y_train_to_clustered[:])):\n",
    "        if cluster_to_num_map[y_train_to_clustered[i][1]] == b[i]:\n",
    "            purity_sums[cluster_to_num_map[y_train_to_clustered[i][0]]] += 1\n",
    "        else:\n",
    "            purity_sums[cluster_to_num_map[y_train_to_clustered[i][0]]] += 1\n",
    "    \n",
    "    print('Purity ', np.add.reduce(purity_sums)[0] / len(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog_train (4005, 128, 128, 3)\n",
      "dog_test (1012, 128, 128, 3)\n",
      "cat_train (4000, 128, 128, 3)\n",
      "cat_test (1011, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "dog_train_path=\"./input/cat-and-dog/training_set/dogs/\"\n",
    "dog_test_path=\"./input/cat-and-dog/test_set/dogs/\"\n",
    "cat_train_path=\"./input/cat-and-dog/training_set/cats/\"\n",
    "cat_test_path=\"./input/cat-and-dog/test_set/cats/\"\n",
    "\n",
    "dog_train=[]\n",
    "for filename in os.listdir(dog_train_path):\n",
    "    if filename.endswith(\".jpg\"):\n",
    "        img=image.load_img(dog_train_path+filename,target_size=(128,128))\n",
    "        dog_train.append(image.img_to_array(img))\n",
    "dog_train=np.array(dog_train)\n",
    "\n",
    "dog_test=[]\n",
    "for filename in os.listdir(dog_test_path):\n",
    "    if filename.endswith(\".jpg\"):\n",
    "        img=image.load_img(dog_test_path+filename,target_size=(128,128))\n",
    "        dog_test.append(image.img_to_array(img))\n",
    "dog_test=np.array(dog_test)\n",
    "\n",
    "cat_train=[]\n",
    "for filename in os.listdir(cat_train_path):\n",
    "    if filename.endswith(\".jpg\"):\n",
    "        img=image.load_img(cat_train_path+filename,target_size=(128,128))\n",
    "        cat_train.append(image.img_to_array(img))\n",
    "cat_train=np.array(cat_train)\n",
    "\n",
    "cat_test=[]\n",
    "for filename in os.listdir(cat_test_path):\n",
    "    if filename.endswith(\".jpg\"):\n",
    "        img=image.load_img(cat_test_path+filename,target_size=(128,128))\n",
    "        cat_test.append(image.img_to_array(img))\n",
    "cat_test=np.array(cat_test)\n",
    "\n",
    "print(\"dog_train\",dog_train.shape)\n",
    "print(\"dog_test\",dog_test.shape)\n",
    "print(\"cat_train\",cat_train.shape)\n",
    "print(\"cat_test\",cat_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 3. KMeans expected <= 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\python\\CNN-AutoEncoder\\k_mean_CAE.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 28>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/python/CNN-AutoEncoder/k_mean_CAE.ipynb#W4sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m x_cat_test \u001b[39m/\u001b[39m\u001b[39m=\u001b[39m\u001b[39m255\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/python/CNN-AutoEncoder/k_mean_CAE.ipynb#W4sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m k_base\u001b[39m=\u001b[39mKMeans(n_clusters\u001b[39m=\u001b[39mn_clusters)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/python/CNN-AutoEncoder/k_mean_CAE.ipynb#W4sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m k_base\u001b[39m.\u001b[39;49mfit([x_dog_train],[x_cat_train])\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/python/CNN-AutoEncoder/k_mean_CAE.ipynb#W4sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m base_clustered\u001b[39m=\u001b[39mk_base\u001b[39m.\u001b[39mpredict(x_dog_train,x_cat_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/python/CNN-AutoEncoder/k_mean_CAE.ipynb#W4sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m print_results(base_clustered,x_dog_train,x_cat_train)\n",
      "File \u001b[1;32mc:\\Users\\gopl0\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1367\u001b[0m, in \u001b[0;36mKMeans.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1341\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   1342\u001b[0m     \u001b[39m\"\"\"Compute k-means clustering.\u001b[39;00m\n\u001b[0;32m   1343\u001b[0m \n\u001b[0;32m   1344\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1365\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1366\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1367\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m   1368\u001b[0m         X,\n\u001b[0;32m   1369\u001b[0m         accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1370\u001b[0m         dtype\u001b[39m=\u001b[39;49m[np\u001b[39m.\u001b[39;49mfloat64, np\u001b[39m.\u001b[39;49mfloat32],\n\u001b[0;32m   1371\u001b[0m         order\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mC\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1372\u001b[0m         copy\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcopy_x,\n\u001b[0;32m   1373\u001b[0m         accept_large_sparse\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m   1374\u001b[0m     )\n\u001b[0;32m   1376\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_params(X)\n\u001b[0;32m   1377\u001b[0m     random_state \u001b[39m=\u001b[39m check_random_state(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrandom_state)\n",
      "File \u001b[1;32mc:\\Users\\gopl0\\anaconda3\\lib\\site-packages\\sklearn\\base.py:577\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    575\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    576\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 577\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    578\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[0;32m    579\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[1;32mc:\\Users\\gopl0\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:893\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    887\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    888\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdtype=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnumeric\u001b[39m\u001b[39m'\u001b[39m\u001b[39m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    889\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    890\u001b[0m     )\n\u001b[0;32m    892\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m allow_nd \u001b[39mand\u001b[39;00m array\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m3\u001b[39m:\n\u001b[1;32m--> 893\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    894\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    895\u001b[0m         \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    896\u001b[0m     )\n\u001b[0;32m    898\u001b[0m \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[0;32m    899\u001b[0m     _assert_all_finite(\n\u001b[0;32m    900\u001b[0m         array,\n\u001b[0;32m    901\u001b[0m         input_name\u001b[39m=\u001b[39minput_name,\n\u001b[0;32m    902\u001b[0m         estimator_name\u001b[39m=\u001b[39mestimator_name,\n\u001b[0;32m    903\u001b[0m         allow_nan\u001b[39m=\u001b[39mforce_all_finite \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mallow-nan\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    904\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with dim 3. KMeans expected <= 2."
     ]
    }
   ],
   "source": [
    "from turtle import shape\n",
    "from sklearn.cluster import KMeans\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# raw_line=None\n",
    "# if  not raw_line == None:\n",
    "#     items=raw_line.split(':')\n",
    "x_dog_train=dog_train.reshape(dog_train.shape[0],-1)\n",
    "x_dog_test=dog_test.reshape(dog_test.shape[0],n_rows, n_cols,3)\n",
    "x_cat_train=cat_train.reshape(cat_train.shape[0],-1)\n",
    "x_cat_test=cat_test.reshape(cat_test.shape[0],n_rows, n_cols,3)\n",
    "# x_dog_train=dog_train.reshape(dog_train.shape[0],49152)\n",
    "# x_dog_test=dog_test.reshape(dog_test.shape[0],49152)\n",
    "\n",
    "input_shape=(n_rows,n_cols,1)\n",
    "\n",
    "x_dog_train=x_dog_train.astype('float32')\n",
    "x_dog_test=x_dog_test.astype('float32')\n",
    "x_dog_train /=255\n",
    "x_dog_test /=255\n",
    "\n",
    "x_cat_train=x_cat_train.astype('float32')\n",
    "x_cat_test=x_cat_test.astype('float32')\n",
    "x_cat_train /=255\n",
    "x_cat_test /=255\n",
    "\n",
    "k_base=KMeans(n_clusters=n_clusters)\n",
    "k_base.fit([x_dog_train],[x_cat_train])\n",
    "\n",
    "base_clustered=k_base.predict(x_dog_train,x_cat_train)\n",
    "print_results(base_clustered,x_dog_train,x_cat_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import Model\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Reshape, BatchNormalization\n",
    "from keras import activations\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dims = 14\n",
    "def get_encoder(x):\n",
    "    x = Conv2D(16, (3, 3), activation=activations.relu, padding='same', name='conv2d16')(x)\n",
    "    x = Flatten(name='flatten')(x)\n",
    "    x = Dense(784, activation=activations.relu, name='dense1')(x)\n",
    "    x = Dense(392, activation=activations.relu, name='dense2')(x)\n",
    "    x = Dense(196, activation=activations.relu, name='dense3')(x)\n",
    "    x = Dense(n_dims, activation=activations.relu, name='denseDim')(x)\n",
    "    return x\n",
    "\n",
    "def get_decoder(x):\n",
    "    x = Dense(196, activation=activations.relu)(x)\n",
    "    x = Dense(392, activation=activations.relu)(x)\n",
    "    x = Dense(784, activation='sigmoid')(x)\n",
    "    x = Reshape((28,28,1))(x)\n",
    "    return x\n",
    "\n",
    "x = Input(shape=(n_rows, n_cols, 1), name='input')\n",
    "\n",
    "encoder = get_encoder(x)\n",
    "decoder = get_decoder(encoder)\n",
    "autoencoder = Model(x, decoder)\n",
    "\n",
    "autoencoder.compile(loss=keras.losses.binary_crossentropy,\n",
    "              optimizer=tf.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "autoencoder.summary()\n",
    "\n",
    "\n",
    "x_dog_train=dog_train.reshape(dog_train.shape[0],-1)\n",
    "x_dog_test=dog_test.reshape(dog_test.shape[0],n_rows, n_cols, 3)\n",
    "x_cat_train=cat_train.reshape(cat_train.shape[0],-1)\n",
    "x_cat_test=cat_test.reshape(cat_test.shape[0],n_rows, n_cols, 3)\n",
    "input_shape = (n_rows, n_cols, 1)\n",
    "\n",
    "x_dog_train = x_dog_train.astype('float32')\n",
    "x_dog_test = x_dog_test.astype('float32')\n",
    "x_dog_train /= 255\n",
    "x_dog_test /= 255\n",
    "\n",
    "x_cat_train = x_dog_train.astype('float32')\n",
    "x_cat_test = x_dog_test.astype('float32')\n",
    "x_cat_train /= 255\n",
    "x_cat_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbs = [keras.callbacks.EarlyStopping(patience=15, monitor='val_loss'), \n",
    "       keras.callbacks.ModelCheckpoint(filepath='auto_encoder_weights.h5',\n",
    "       save_best_only=True)]\n",
    "\n",
    "training_results = autoencoder.fit(x_dog_train, x_cat_train,\n",
    "          batch_size=100,\n",
    "          epochs=100,\n",
    "          verbose=1,\n",
    "          validation_data=(x_dog_test, x_cat_test),\n",
    "          callbacks=cbs)\n",
    "print('complete')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cf2ce59cd14ccf06ee242bff7c016a1e75b61f8bcefb1a770f775dab1f551b87"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
